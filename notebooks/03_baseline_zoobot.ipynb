{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 03 — Zoobot Baseline: EfficientNet-B0 Reproduction\n",
    "\n",
    "**Goal**: Train and evaluate the Zoobot-style EfficientNet-B0 baseline on Euclid Q1 data.\n",
    "\n",
    "This notebook:\n",
    "1. Loads the data pipeline (splits, transforms, DataLoaders)\n",
    "2. Creates the Zoobot model (EfficientNet-B0 + regression head)\n",
    "3. Trains with Dirichlet-Multinomial loss (matching Zoobot)\n",
    "4. Two-phase training: linear probe (5 epochs) → full fine-tune (25 epochs)\n",
    "5. Evaluates with per-question metrics and TTA\n",
    "6. Saves results for later model comparison (notebook 05)\n",
    "\n",
    "**Runtime**: ~20 min on T4, ~10 min on A100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": "## 0. Colab Setup\n\nRun this cell **only on Google Colab** — it clones the repo, installs dependencies, and downloads the data. Skip if running locally."
  },
  {
   "cell_type": "code",
   "id": "xnr35yll5ki",
   "source": "import os\n\nIN_COLAB = 'COLAB_GPU' in os.environ or 'google.colab' in str(get_ipython())\n\nif IN_COLAB:\n    # 1. Clone the repo (dev branch has all source code)\n    REPO_URL = 'https://github.com/Smooth-Cactus0/euclid-q1-vit-morphology.git'\n    REPO_DIR = '/content/euclid-q1-vit-morphology'\n\n    if not os.path.exists(REPO_DIR):\n        print('Cloning repository (dev branch)...')\n        !git clone --branch dev {REPO_URL} {REPO_DIR}\n    os.chdir(REPO_DIR)\n    print(f'Working directory: {os.getcwd()}')\n\n    # 2. Install dependencies\n    print('\\nInstalling dependencies...')\n    !pip install -q timm tqdm scipy\n\n    # 3. Download catalog\n    CATALOG_PATH = 'data/raw/morphology_catalogue.parquet'\n    if not os.path.exists(CATALOG_PATH):\n        print('\\nDownloading catalog...')\n        !python scripts/download_catalog.py\n\n    # 4. Generate splits\n    SPLIT_PATH = 'data/processed/split_indices.json'\n    if not os.path.exists(SPLIT_PATH):\n        print('\\nGenerating train/val/test splits...')\n        !python scripts/prepare_splits.py\n\n    # 5. Download and extract images (~3.8 GB, takes ~5 min)\n    IMAGE_DIR = 'data/raw/images'\n    if not os.path.exists(IMAGE_DIR) or len(os.listdir(IMAGE_DIR)) < 10:\n        print('\\nDownloading images (~3.8 GB)... This takes ~5 minutes.')\n        !python scripts/download_images.py\n    else:\n        n_tiles = len([d for d in os.listdir(IMAGE_DIR) if os.path.isdir(os.path.join(IMAGE_DIR, d))])\n        print(f'\\nImages already present: {n_tiles} tiles')\n\n    print('\\nColab setup complete!')\nelse:\n    print('Not running on Colab — skipping setup.')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ksocqkpy2bi",
   "source": "## 1. Setup",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "import sys\nfrom pathlib import Path\nimport os\n\n# Set project root — Colab runs from repo root, local runs from notebooks/\nif 'COLAB_GPU' in os.environ or 'google.colab' in str(get_ipython()):\n    PROJECT_ROOT = Path('/content/euclid-q1-vit-morphology')\nelse:\n    PROJECT_ROOT = Path('..').resolve()\n\n# Ensure project root is on sys.path (remove stale entries first)\nproject_str = str(PROJECT_ROOT)\nsys.path = [p for p in sys.path if p != project_str]\nsys.path.insert(0, project_str)\n\nprint(f'PROJECT_ROOT: {PROJECT_ROOT}')\nprint(f'src/ exists: {(PROJECT_ROOT / \"src\").exists()}')\nprint(f'src/data/dataset.py exists: {(PROJECT_ROOT / \"src\" / \"data\" / \"dataset.py\").exists()}')\n\nimport json\nimport time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import DataLoader\n\nfrom src.data.dataset import EuclidDataset, MorphologySchema\nfrom src.data.transforms import get_transforms, get_tta_transforms\nfrom src.models.factory import create_model\nfrom src.training.losses import DirichletMultinomialLoss\nfrom src.training.trainer import Trainer, TrainConfig\nfrom src.evaluation.metrics import (\n    compute_metrics,\n    compute_per_question_metrics,\n    bootstrap_confidence_interval,\n)\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.rcParams['figure.dpi'] = 120\n\n# Reproducibility\nSEED = 42\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'\\nDevice: {device}')\nif torch.cuda.is_available():\n    print(f'GPU: {torch.cuda.get_device_name()}')\n    print(f'Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "CATALOG_PATH = PROJECT_ROOT / 'data' / 'raw' / 'morphology_catalogue.parquet'\n",
    "SPLIT_PATH = PROJECT_ROOT / 'data' / 'processed' / 'split_indices.json'\n",
    "IMAGE_DIR = PROJECT_ROOT / 'data' / 'raw' / 'images'\n",
    "CHECKPOINT_DIR = PROJECT_ROOT / 'results' / 'checkpoints'\n",
    "FIGURES_DIR = PROJECT_ROOT / 'results' / 'figures'\n",
    "TABLES_DIR = PROJECT_ROOT / 'results' / 'tables'\n",
    "\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TABLES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Training hyperparameters (from configs/base.yaml)\n",
    "MODEL_NAME = 'zoobot'\n",
    "INPUT_SIZE = 224\n",
    "BATCH_SIZE = 32          # Increase to 64 on A100\n",
    "LR_PROBE = 1e-3          # Linear probe learning rate\n",
    "LR_FINETUNE = 5e-5       # Full fine-tune learning rate\n",
    "WEIGHT_DECAY = 0.01\n",
    "LINEAR_PROBE_EPOCHS = 5\n",
    "FINETUNE_EPOCHS = 25\n",
    "PATIENCE = 5\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# Adjust batch size for GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_mem / 1e9\n",
    "    if gpu_mem > 30:       # A100\n",
    "        BATCH_SIZE = 64\n",
    "    elif gpu_mem > 14:     # V100 / T4\n",
    "        BATCH_SIZE = 32\n",
    "    else:\n",
    "        BATCH_SIZE = 16\n",
    "\n",
    "print(f'Model: {MODEL_NAME}')\n",
    "print(f'Batch size: {BATCH_SIZE}')\n",
    "print(f'Training: {LINEAR_PROBE_EPOCHS} probe + {FINETUNE_EPOCHS} fine-tune epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 3. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema\n",
    "schema = MorphologySchema.default()\n",
    "print(f'Schema: {schema.num_outputs} outputs across {len(schema.questions)} questions')\n",
    "\n",
    "# Load splits\n",
    "train_df = EuclidDataset.load_split(CATALOG_PATH, SPLIT_PATH, 'train')\n",
    "val_df = EuclidDataset.load_split(CATALOG_PATH, SPLIT_PATH, 'val')\n",
    "test_df = EuclidDataset.load_split(CATALOG_PATH, SPLIT_PATH, 'test')\n",
    "\n",
    "print(f'\\nTrain: {len(train_df):,}')\n",
    "print(f'Val:   {len(val_df):,}')\n",
    "print(f'Test:  {len(test_df):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation config (matching configs/base.yaml)\n",
    "augmentation_cfg = {\n",
    "    'random_horizontal_flip': True,\n",
    "    'random_vertical_flip': True,\n",
    "    'random_rotation': 360,\n",
    "    'color_jitter': {\n",
    "        'brightness': 0.1,\n",
    "        'contrast': 0.1,\n",
    "        'saturation': 0.0,\n",
    "        'hue': 0.0,\n",
    "    },\n",
    "    'random_resized_crop': {\n",
    "        'scale': [0.85, 1.0],\n",
    "        'ratio': [0.95, 1.05],\n",
    "    },\n",
    "}\n",
    "\n",
    "train_transform = get_transforms('train', INPUT_SIZE, augmentation_cfg=augmentation_cfg)\n",
    "val_transform = get_transforms('val', INPUT_SIZE)\n",
    "\n",
    "# Datasets\n",
    "train_ds = EuclidDataset(train_df, IMAGE_DIR, schema, train_transform)\n",
    "val_ds = EuclidDataset(val_df, IMAGE_DIR, schema, val_transform)\n",
    "test_ds = EuclidDataset(test_df, IMAGE_DIR, schema, val_transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True, drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True,\n",
    ")\n",
    "\n",
    "print(f'Train: {len(train_ds):,} samples ({len(train_loader)} batches)')\n",
    "print(f'Val:   {len(val_ds):,} samples ({len(val_loader)} batches)')\n",
    "print(f'Test:  {len(test_ds):,} samples ({len(test_loader)} batches)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model('zoobot', num_outputs=schema.num_outputs, pretrained=True)\n",
    "params = model.count_parameters()\n",
    "\n",
    "print(f'Model: {MODEL_NAME} (EfficientNet-B0)')\n",
    "print(f'Parameters: {params[\"total\"]:,} total, {params[\"trainable\"]:,} trainable')\n",
    "print(f'Output dim: {schema.num_outputs}')\n",
    "\n",
    "# Quick sanity check — forward pass with random input\n",
    "with torch.no_grad():\n",
    "    dummy = torch.randn(2, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "    out = model(dummy)\n",
    "    print(f'\\nForward pass OK: input {dummy.shape} → output {out.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5. Training\n",
    "\n",
    "Two-phase training strategy:\n",
    "- **Phase 1 (Linear Probe)**: Freeze the EfficientNet backbone, train only the new regression head for 5 epochs at lr=1e-3. This quickly establishes a reasonable mapping from pretrained features to vote fractions.\n",
    "- **Phase 2 (Full Fine-tune)**: Unfreeze all layers, train end-to-end for 25 epochs at lr=5e-5 with cosine annealing. Early stopping (patience=5) prevents overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function (Dirichlet-Multinomial — matching Zoobot)\n",
    "criterion = DirichletMultinomialLoss(schema)\n",
    "\n",
    "# Trainer config\n",
    "train_config = TrainConfig(\n",
    "    lr=LR_FINETUNE,\n",
    "    lr_linear_probe=LR_PROBE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=LINEAR_PROBE_EPOCHS + FINETUNE_EPOCHS,\n",
    "    linear_probe_epochs=LINEAR_PROBE_EPOCHS,\n",
    "    full_finetune_epochs=FINETUNE_EPOCHS,\n",
    "    warmup_fraction=0.05,\n",
    "    patience=PATIENCE,\n",
    "    checkpoint_dir=str(CHECKPOINT_DIR),\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    config=train_config,\n",
    "    device=device,\n",
    "    model_name=MODEL_NAME,\n",
    ")\n",
    "\n",
    "print('Starting training...')\n",
    "t_start = time.time()\n",
    "summary = trainer.train()\n",
    "t_total = time.time() - t_start\n",
    "\n",
    "print(f'\\nTotal training time: {t_total/60:.1f} min')\n",
    "print(f'Best val_loss: {summary[\"best_val_loss\"]:.4f} (epoch {summary[\"best_epoch\"]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 6. Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(trainer.history)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss curves\n",
    "ax = axes[0]\n",
    "ax.plot(history['epoch'], history['train_loss'], 'b-', label='Train', alpha=0.8)\n",
    "ax.plot(history['epoch'], history['val_loss'], 'r-', label='Val', alpha=0.8)\n",
    "best_epoch = summary['best_epoch']\n",
    "best_loss = summary['best_val_loss']\n",
    "ax.axvline(best_epoch, color='gray', linestyle='--', alpha=0.5, label=f'Best (epoch {best_epoch})')\n",
    "ax.scatter([best_epoch], [best_loss], color='red', zorder=5, s=50)\n",
    "\n",
    "# Mark phase boundary\n",
    "probe_epochs = history[history['phase'] == 'probe']\n",
    "if len(probe_epochs) > 0:\n",
    "    boundary = probe_epochs['epoch'].max() + 0.5\n",
    "    ax.axvline(boundary, color='green', linestyle=':', alpha=0.5, label='Phase boundary')\n",
    "\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Dirichlet-Multinomial Loss')\n",
    "ax.set_title('Training & Validation Loss')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate schedule\n",
    "ax = axes[1]\n",
    "ax.plot(history['epoch'], history['lr'], 'g-', linewidth=2)\n",
    "if len(probe_epochs) > 0:\n",
    "    ax.axvline(boundary, color='green', linestyle=':', alpha=0.5)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Learning Rate')\n",
    "ax.set_title('LR Schedule')\n",
    "ax.set_yscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Epoch timing\n",
    "ax = axes[2]\n",
    "colors = ['steelblue' if p == 'probe' else 'coral' for p in history['phase']]\n",
    "ax.bar(history['epoch'], history['time_s'], color=colors, alpha=0.7)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Time (s)')\n",
    "ax.set_title('Epoch Duration')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "fig.suptitle(f'Zoobot (EfficientNet-B0) Training — Best val_loss: {best_loss:.4f}', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'zoobot_training_curves.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 7. Test Set Evaluation\n",
    "\n",
    "Load the best checkpoint and evaluate on the held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best checkpoint\n",
    "best_ckpt = CHECKPOINT_DIR / f'{MODEL_NAME}_best.pt'\n",
    "model.load_state_dict(torch.load(best_ckpt, map_location=device, weights_only=True))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(f'Loaded best checkpoint: {best_ckpt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(model, loader, device, apply_activation=True):\n",
    "    \"\"\"Run inference and collect predictions, targets, masks.\"\"\"\n",
    "    all_preds, all_targets, all_masks = [], [], []\n",
    "    \n",
    "    for images, targets, masks in loader:\n",
    "        images = images.to(device)\n",
    "        logits = model(images)\n",
    "        \n",
    "        if apply_activation:\n",
    "            # For evaluation: convert logits to vote fractions\n",
    "            # Apply softmax per question group to get proper fractions\n",
    "            preds = torch.zeros_like(logits)\n",
    "            schema = MorphologySchema.default()\n",
    "            for q, (start, end) in schema.question_slices.items():\n",
    "                preds[:, start:end] = torch.softmax(logits[:, start:end], dim=1)\n",
    "        else:\n",
    "            preds = logits\n",
    "        \n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_targets.append(targets.numpy())\n",
    "        all_masks.append(masks.numpy())\n",
    "    \n",
    "    return (\n",
    "        np.concatenate(all_preds),\n",
    "        np.concatenate(all_targets),\n",
    "        np.concatenate(all_masks),\n",
    "    )\n",
    "\n",
    "\n",
    "# Standard evaluation (no TTA)\n",
    "print('Running inference on test set...')\n",
    "test_preds, test_targets, test_masks = predict(model, test_loader, device)\n",
    "print(f'Predictions shape: {test_preds.shape}')\n",
    "print(f'Targets shape:     {test_targets.shape}')\n",
    "print(f'Masks shape:       {test_masks.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate metrics\n",
    "metrics = compute_metrics(test_preds, test_targets, test_masks, schema)\n",
    "\n",
    "print('=' * 60)\n",
    "print(f'ZOOBOT BASELINE — TEST SET METRICS (no TTA)')\n",
    "print('=' * 60)\n",
    "for name, value in sorted(metrics.items()):\n",
    "    if name.endswith('_p'):  # Skip p-values for display\n",
    "        continue\n",
    "    print(f'  {name:25s}: {value:.4f}')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-question metrics\n",
    "per_q = compute_per_question_metrics(test_preds, test_targets, test_masks, schema)\n",
    "\n",
    "print(f'\\n{\"Question\":30s} {\"N\":>8s} {\"MSE\":>8s} {\"MAE\":>8s} {\"R²\":>8s} {\"Pearson\":>8s} {\"Acc\":>8s}')\n",
    "print('-' * 90)\n",
    "for question, qm in per_q.items():\n",
    "    if qm.get('n_valid', 0) == 0:\n",
    "        print(f'{question:30s} {0:>8d}   (no valid samples)')\n",
    "        continue\n",
    "    print(\n",
    "        f'{question:30s} '\n",
    "        f'{qm[\"n_valid\"]:>8,d} '\n",
    "        f'{qm[\"mse\"]:>8.4f} '\n",
    "        f'{qm[\"mae\"]:>8.4f} '\n",
    "        f'{qm.get(\"r2\", float(\"nan\")):>8.4f} '\n",
    "        f'{qm.get(\"pearson_r\", float(\"nan\")):>8.4f} '\n",
    "        f'{qm.get(\"accuracy\", float(\"nan\")):>8.4f}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 8. Test-Time Augmentation (TTA)\n",
    "\n",
    "Apply 7 geometric transforms (original + flips + rotations), average predictions.\n",
    "This is \"free\" — no additional training, just inference passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_with_tta(model, dataset_df, image_dir, schema, device, batch_size=32, num_workers=4):\n",
    "    \"\"\"Run TTA inference: predict with each transform, then average.\"\"\"\n",
    "    tta_transforms = get_tta_transforms()\n",
    "    print(f'TTA with {len(tta_transforms)} views')\n",
    "    \n",
    "    all_view_preds = []\n",
    "    \n",
    "    for i, tfm in enumerate(tta_transforms):\n",
    "        ds = EuclidDataset(dataset_df, image_dir, schema, tfm)\n",
    "        loader = DataLoader(\n",
    "            ds, batch_size=batch_size, shuffle=False,\n",
    "            num_workers=num_workers, pin_memory=True,\n",
    "        )\n",
    "        \n",
    "        preds_list = []\n",
    "        for images, _, _ in loader:\n",
    "            images = images.to(device)\n",
    "            logits = model(images)\n",
    "            \n",
    "            # Convert to fractions via per-question softmax\n",
    "            preds = torch.zeros_like(logits)\n",
    "            for q, (start, end) in schema.question_slices.items():\n",
    "                preds[:, start:end] = torch.softmax(logits[:, start:end], dim=1)\n",
    "            \n",
    "            preds_list.append(preds.cpu().numpy())\n",
    "        \n",
    "        view_preds = np.concatenate(preds_list)\n",
    "        all_view_preds.append(view_preds)\n",
    "        print(f'  View {i+1}/{len(tta_transforms)} done')\n",
    "    \n",
    "    # Average across TTA views\n",
    "    tta_preds = np.mean(all_view_preds, axis=0)\n",
    "    \n",
    "    # Collect targets and masks from original dataset\n",
    "    orig_ds = EuclidDataset(dataset_df, image_dir, schema, get_transforms('val'))\n",
    "    targets = orig_ds.targets.numpy()\n",
    "    masks = orig_ds.masks.numpy()\n",
    "    \n",
    "    return tta_preds, targets, masks\n",
    "\n",
    "\n",
    "print('Running TTA on test set...')\n",
    "t0 = time.time()\n",
    "tta_preds, tta_targets, tta_masks = predict_with_tta(\n",
    "    model, test_df, IMAGE_DIR, schema, device,\n",
    "    batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,\n",
    ")\n",
    "tta_time = time.time() - t0\n",
    "print(f'\\nTTA inference time: {tta_time:.1f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA metrics\n",
    "tta_metrics = compute_metrics(tta_preds, tta_targets, tta_masks, schema)\n",
    "\n",
    "print('=' * 60)\n",
    "print(f'ZOOBOT BASELINE — TEST SET METRICS (with TTA)')\n",
    "print('=' * 60)\n",
    "for name, value in sorted(tta_metrics.items()):\n",
    "    if name.endswith('_p'):\n",
    "        continue\n",
    "    no_tta = metrics.get(name, float('nan'))\n",
    "    delta = value - no_tta if not np.isnan(no_tta) else float('nan')\n",
    "    arrow = '↑' if delta > 0 and name in ('r2', 'pearson_r', 'spearman_r', 'accuracy_mean', 'f1_weighted_mean') else \\\n",
    "            '↓' if delta < 0 and name in ('r2', 'pearson_r', 'spearman_r', 'accuracy_mean', 'f1_weighted_mean') else \\\n",
    "            '↓' if delta < 0 and name in ('mse', 'mae') else \\\n",
    "            '↑' if delta > 0 and name in ('mse', 'mae') else ''\n",
    "    print(f'  {name:25s}: {value:.4f}  (Δ={delta:+.4f} {arrow})')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 9. Bootstrap Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def mse_metric(preds, targets, masks):\n",
    "    valid = masks.astype(bool).flatten()\n",
    "    return mean_squared_error(targets.flatten()[valid], preds.flatten()[valid])\n",
    "\n",
    "def r2_metric(preds, targets, masks):\n",
    "    valid = masks.astype(bool).flatten()\n",
    "    return r2_score(targets.flatten()[valid], preds.flatten()[valid])\n",
    "\n",
    "print('Computing bootstrap CIs (1000 iterations)...')\n",
    "print('This may take a minute.\\n')\n",
    "\n",
    "# MSE CI (with TTA)\n",
    "mse_point, mse_lo, mse_hi = bootstrap_confidence_interval(\n",
    "    tta_preds, tta_targets, tta_masks, mse_metric, n_iterations=1000,\n",
    ")\n",
    "print(f'MSE (TTA):  {mse_point:.4f}  [{mse_lo:.4f}, {mse_hi:.4f}]')\n",
    "\n",
    "# R² CI (with TTA)\n",
    "r2_point, r2_lo, r2_hi = bootstrap_confidence_interval(\n",
    "    tta_preds, tta_targets, tta_masks, r2_metric, n_iterations=1000,\n",
    ")\n",
    "print(f'R² (TTA):   {r2_point:.4f}  [{r2_lo:.4f}, {r2_hi:.4f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 10. Predicted vs True Vote Fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots: predicted vs true for top-level questions\n",
    "key_questions = ['smooth-or-featured', 'merging', 'disk-edge-on', 'has-spiral-arms']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "for ax, question in zip(axes.flat, key_questions):\n",
    "    start, end = schema.question_slices[question]\n",
    "    q_mask = tta_masks[:, start] > 0\n",
    "    \n",
    "    if q_mask.sum() == 0:\n",
    "        ax.set_title(f'{question} (no valid samples)')\n",
    "        continue\n",
    "    \n",
    "    # Use the first answer column as the main fraction to plot\n",
    "    pred_frac = tta_preds[q_mask, start]\n",
    "    true_frac = tta_targets[q_mask, start]\n",
    "    answer_name = schema.questions[question][0]\n",
    "    \n",
    "    ax.scatter(true_frac, pred_frac, alpha=0.05, s=1, color='steelblue')\n",
    "    ax.plot([0, 1], [0, 1], 'r--', linewidth=1, alpha=0.8)\n",
    "    \n",
    "    # Correlation\n",
    "    from scipy import stats\n",
    "    r, _ = stats.pearsonr(true_frac, pred_frac)\n",
    "    \n",
    "    ax.set_xlabel(f'True {answer_name} fraction')\n",
    "    ax.set_ylabel(f'Predicted {answer_name} fraction')\n",
    "    ax.set_title(f'{question} (r={r:.3f}, N={q_mask.sum():,})')\n",
    "    ax.set_xlim(-0.02, 1.02)\n",
    "    ax.set_ylim(-0.02, 1.02)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "fig.suptitle('Zoobot Baseline: Predicted vs True Vote Fractions (TTA)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'zoobot_pred_vs_true.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## 11. Per-Question Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-question metrics (with TTA)\n",
    "tta_per_q = compute_per_question_metrics(tta_preds, tta_targets, tta_masks, schema)\n",
    "\n",
    "# Build a summary DataFrame\n",
    "rows = []\n",
    "for question, qm in tta_per_q.items():\n",
    "    if qm.get('n_valid', 0) == 0:\n",
    "        continue\n",
    "    rows.append({\n",
    "        'question': question,\n",
    "        'n_valid': qm['n_valid'],\n",
    "        'mse': qm['mse'],\n",
    "        'mae': qm['mae'],\n",
    "        'r2': qm.get('r2', np.nan),\n",
    "        'pearson_r': qm.get('pearson_r', np.nan),\n",
    "        'accuracy': qm.get('accuracy', np.nan),\n",
    "        'f1_weighted': qm.get('f1_weighted', np.nan),\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "print(results_df.to_string(index=False, float_format='{:.4f}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart: R² and accuracy per question\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "questions = results_df['question']\n",
    "x = np.arange(len(questions))\n",
    "\n",
    "# R² per question\n",
    "ax = axes[0]\n",
    "colors = plt.cm.Set2(np.linspace(0, 1, len(questions)))\n",
    "bars = ax.barh(x, results_df['r2'], color=colors, edgecolor='gray', alpha=0.8)\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(questions, fontsize=10)\n",
    "ax.set_xlabel('R²')\n",
    "ax.set_title('R² per Morphology Question')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "for bar, val in zip(bars, results_df['r2']):\n",
    "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height()/2,\n",
    "            f'{val:.3f}', va='center', fontsize=9)\n",
    "\n",
    "# Accuracy per question\n",
    "ax = axes[1]\n",
    "bars = ax.barh(x, results_df['accuracy'], color=colors, edgecolor='gray', alpha=0.8)\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(questions, fontsize=10)\n",
    "ax.set_xlabel('Accuracy (argmax)')\n",
    "ax.set_title('Classification Accuracy per Question')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "for bar, val in zip(bars, results_df['accuracy']):\n",
    "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height()/2,\n",
    "            f'{val:.3f}', va='center', fontsize=9)\n",
    "\n",
    "fig.suptitle('Zoobot Baseline: Per-Question Performance (with TTA)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'zoobot_per_question_metrics.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## 12. Save Results\n",
    "\n",
    "Save all results for later comparison with ViT models in notebook 05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comprehensive results\n",
    "results = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'architecture': 'EfficientNet-B0',\n",
    "    'pretrained': 'ImageNet',\n",
    "    'params_total': params['total'],\n",
    "    'params_trainable': params['trainable'],\n",
    "    'training': {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'lr_probe': LR_PROBE,\n",
    "        'lr_finetune': LR_FINETUNE,\n",
    "        'linear_probe_epochs': LINEAR_PROBE_EPOCHS,\n",
    "        'finetune_epochs': FINETUNE_EPOCHS,\n",
    "        'total_epochs_trained': len(trainer.history),\n",
    "        'best_epoch': summary['best_epoch'],\n",
    "        'best_val_loss': summary['best_val_loss'],\n",
    "        'training_time_min': t_total / 60,\n",
    "    },\n",
    "    'metrics_no_tta': metrics,\n",
    "    'metrics_tta': tta_metrics,\n",
    "    'per_question_tta': {q: dict(m) for q, m in tta_per_q.items()},\n",
    "    'bootstrap_ci': {\n",
    "        'mse': {'point': mse_point, 'ci_lower': mse_lo, 'ci_upper': mse_hi},\n",
    "        'r2': {'point': r2_point, 'ci_lower': r2_lo, 'ci_upper': r2_hi},\n",
    "    },\n",
    "}\n",
    "\n",
    "# Save JSON\n",
    "results_path = TABLES_DIR / f'{MODEL_NAME}_results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2, default=float)\n",
    "print(f'Results saved: {results_path}')\n",
    "\n",
    "# Save predictions for post-hoc analysis\n",
    "np.savez_compressed(\n",
    "    TABLES_DIR / f'{MODEL_NAME}_predictions.npz',\n",
    "    predictions=tta_preds,\n",
    "    targets=tta_targets,\n",
    "    masks=tta_masks,\n",
    ")\n",
    "print(f'Predictions saved: {TABLES_DIR / f\"{MODEL_NAME}_predictions.npz\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-question results table (CSV for LaTeX)\n",
    "results_df.to_csv(TABLES_DIR / f'{MODEL_NAME}_per_question.csv', index=False)\n",
    "print(f'Per-question CSV saved: {TABLES_DIR / f\"{MODEL_NAME}_per_question.csv\"}')\n",
    "\n",
    "# Training history CSV\n",
    "history.to_csv(TABLES_DIR / f'{MODEL_NAME}_history.csv', index=False)\n",
    "print(f'Training history saved: {TABLES_DIR / f\"{MODEL_NAME}_history.csv\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "## 13. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 60)\n",
    "print('ZOOBOT BASELINE — FINAL SUMMARY')\n",
    "print('=' * 60)\n",
    "print(f'''\n",
    "  Model:          {MODEL_NAME} (EfficientNet-B0)\n",
    "  Parameters:     {params[\"total\"]:,} total, {params[\"trainable\"]:,} trainable\n",
    "  Training:       {LINEAR_PROBE_EPOCHS} probe + {len(trainer.history) - LINEAR_PROBE_EPOCHS} fine-tune epochs\n",
    "  Best epoch:     {summary[\"best_epoch\"]}\n",
    "  Training time:  {t_total/60:.1f} min\n",
    "\n",
    "  --- Metrics (no TTA) ---\n",
    "  MSE:            {metrics[\"mse\"]:.4f}\n",
    "  MAE:            {metrics[\"mae\"]:.4f}\n",
    "  R²:             {metrics[\"r2\"]:.4f}\n",
    "  Pearson r:      {metrics.get(\"pearson_r\", float(\"nan\")):.4f}\n",
    "  Accuracy:       {metrics.get(\"accuracy_mean\", float(\"nan\")):.4f}\n",
    "\n",
    "  --- Metrics (with TTA) ---\n",
    "  MSE:            {tta_metrics[\"mse\"]:.4f}  [{mse_lo:.4f}, {mse_hi:.4f}]\n",
    "  MAE:            {tta_metrics[\"mae\"]:.4f}\n",
    "  R²:             {tta_metrics[\"r2\"]:.4f}  [{r2_lo:.4f}, {r2_hi:.4f}]\n",
    "  Pearson r:      {tta_metrics.get(\"pearson_r\", float(\"nan\")):.4f}\n",
    "  Accuracy:       {tta_metrics.get(\"accuracy_mean\", float(\"nan\")):.4f}\n",
    "''')\n",
    "print('=' * 60)\n",
    "print('\\nNext: notebooks/04_vit_experiments.ipynb')\n",
    "print('  Train ViT-Base, Swin-V2, DINOv2, and ConvNeXt on the same data.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}